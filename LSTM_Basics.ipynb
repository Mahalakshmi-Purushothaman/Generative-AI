{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858a49ec-bfdf-4b76-b712-a8a243786d8d",
   "metadata": {},
   "source": [
    "Long Short-Term Memory (LSTM) is a type of Recurrent Neural Network (RNN) architecture used for sequence prediction problems. LSTMs are particularly useful for tasks where the data has temporal dependencies, i.e., the output depends not only on the current input but also on previous time steps. These models are specifically designed to handle issues such as vanishing gradients, which RNNs traditionally struggle with, by incorporating memory cells.\n",
    "\n",
    "Key Terminologies in LSTM\n",
    "Cell State: The \"memory\" of the LSTM unit that carries information across time steps. It is modified by different gates and allows long-term dependencies to be captured.\n",
    "\n",
    "Forget Gate: Decides what information from the previous time step should be discarded from the cell state. This gate outputs a number between 0 and 1, where 0 means \"completely forget\" and 1 means \"completely retain.\"\n",
    "\n",
    "Input Gate: Controls what new information should be added to the cell state. This gate decides how much of the incoming data will be stored in memory.\n",
    "\n",
    "Output Gate: Determines the next hidden state (i.e., output) based on the cell state. It decides which part of the cell state should be output to the next time step or layer.\n",
    "\n",
    "Hidden State: Contains the output of the LSTM unit and is used for predictions at each time step.\n",
    "\n",
    "Types of LSTM\n",
    "Vanilla LSTM: The standard LSTM architecture where all gates are computed using fully connected layers.\n",
    "\n",
    "Bidirectional LSTM: This is a modification where two LSTM networks are used: one processes the sequence from left to right, and the other from right to left. This architecture is beneficial when future context is important.\n",
    "\n",
    "Stacked LSTM: Involves multiple LSTM layers stacked on top of each other. This helps the model capture higher-level features.\n",
    "\n",
    "Attention-based LSTM: This combines the LSTM with an attention mechanism, allowing the model to focus on specific parts of the input sequence when making predictions.\n",
    "\n",
    "When to Use LSTM and When Not to Use It\n",
    "When to Use LSTM:\n",
    "Sequential Data: When your data has temporal dependencies, such as time series data (financial, medical, weather data).\n",
    "Long-term Dependencies: When the model needs to remember information over longer periods, like in natural language processing (NLP) tasks, speech recognition, or stock market prediction.\n",
    "Predicting Future Values: LSTMs are suitable for predicting future values based on past data (e.g., stock prices, patient health trends).\n",
    "When Not to Use LSTM:\n",
    "Short-term Dependencies: If the task requires understanding short-term dependencies, a simple feedforward neural network or CNN might perform better than LSTM.\n",
    "Tabular Data: For structured data like typical databases, tabular data (e.g., customer information), traditional models such as decision trees, SVMs, or XGBoost might be more effective.\n",
    "Large Sequence Length: LSTMs can struggle with very long sequences, where they may still have difficulty capturing long-range dependencies due to vanishing gradients.\n",
    "Best Practices for Using LSTM\n",
    "Preprocessing: Proper scaling/normalization of data (e.g., MinMax scaling) before feeding it into the model.\n",
    "Sequence Padding: Ensure that all input sequences have the same length by padding or truncating sequences.\n",
    "Regularization: Use dropout or L2 regularization to avoid overfitting.\n",
    "Hyperparameter Tuning: Tune the number of LSTM units, batch size, learning rate, and number of layers.\n",
    "Gradient Clipping: Prevent exploding gradients by clipping gradients during training.\n",
    "Early Stopping: Implement early stopping to halt training when the validation performance stops improving.\n",
    "Potential Key Factors to Keep in Mind\n",
    "Data Quality: Ensure the data is clean and properly labeled. For time series data, make sure there are no missing values, and if there are, handle them appropriately (e.g., forward fill, interpolation).\n",
    "Sequence Length: LSTM performance can degrade with very long sequences. Consider reducing sequence length or using advanced architectures like attention mechanisms.\n",
    "Model Complexity: LSTMs can be computationally expensive. Use stacked LSTMs only when necessary to avoid excessive training time.\n",
    "Learning Rate: Use a smaller learning rate for fine-tuning and avoid overshooting during training.\n",
    "Banking - Predicting Stock Prices (Time Series Forecasting)\n",
    "In banking, LSTMs can predict future stock prices based on historical data.\n",
    "Business Scenario:\n",
    "\n",
    "Use Case: Banks can use LSTM for predicting future stock prices, helping traders make informed decisions about buying and selling stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea5ea3-7fb6-45e9-8b98-cdbab4b4b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load stock data\n",
    "data = pd.read_csv('stock_prices.csv')  # Use a CSV with historical stock data\n",
    "data = data[['Date', 'Close']]\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "# Prepare data for LSTM\n",
    "def create_dataset(dataset, time_step=60):\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        X.append(dataset[i:(i+time_step), 0])\n",
    "        y.append(dataset[i+time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_step = 60\n",
    "X, y = create_dataset(scaled_data, time_step)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict stock prices\n",
    "predicted_stock_price = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "predicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(y_test, color='blue', label='Real Stock Price')\n",
    "plt.plot(predicted_stock_price, color='red', label='Predicted Stock Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335beb5-a66f-4737-bb45-c369b49acd15",
   "metadata": {},
   "source": [
    "2. Healthcare - Predicting Disease Progression (Time Series Data)\n",
    "LSTMs can be used to predict the progression of diseases like diabetes or heart conditions based on patient data over time.\n",
    "Business Scenario:\n",
    "\n",
    "Use Case: Healthcare organizations can predict the progression of diseases like diabetes, enabling doctors to adjust treatments proactively based on predicted trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d7c64-05e8-485b-85fc-f4630561fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load healthcare data (patient data over time)\n",
    "data = pd.read_csv('patient_data.csv')  # Data should have patient features over time\n",
    "data = data[['Date', 'GlucoseLevel']]  # Example: predicting glucose levels over time\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data['GlucoseLevel'].values.reshape(-1, 1))\n",
    "\n",
    "# Prepare data for LSTM\n",
    "def create_dataset(dataset, time_step=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        X.append(dataset[i:(i+time_step), 0])\n",
    "        y.append(dataset[i+time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_step = 30\n",
    "X, y = create_dataset(scaled_data, time_step)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict disease progression\n",
    "predicted_glucose = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "predicted_glucose = scaler.inverse_transform(predicted_glucose)\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(y_test, color='blue', label='Real Glucose Levels')\n",
    "plt.plot(predicted_glucose, color='red', label='Predicted Glucose Levels')\n",
    "plt.title('Diabetes Progression Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Glucose Level')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9102d-fa5f-45bf-b0dd-563b5f4cdb32",
   "metadata": {},
   "source": [
    "3. Insurance - Predicting Claim Amounts\n",
    "Insurance companies can use LSTMs to predict claim amounts based on historical claims data over time.\n",
    "Business Scenario:\n",
    "\n",
    "Use Case: Insurance companies can predict future claims amounts based on historical claim data, which helps in better financial planning and risk management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e657d-3af6-401a-8515-b9e76f552960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load insurance claims data\n",
    "data = pd.read_csv('insurance_claims.csv')  # Claim amounts over time\n",
    "data = data[['Date', 'ClaimAmount']]\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data['ClaimAmount'].values.reshape(-1, 1))\n",
    "\n",
    "# Prepare data for LSTM\n",
    "def create_dataset(dataset, time_step=60):\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        X.append(dataset[i:(i+time_step), 0])\n",
    "        y.append(dataset[i+time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_step = 60\n",
    "X, y = create_dataset(scaled_data, time_step)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict claim amounts\n",
    "predicted_claims = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "predicted_claims = scaler.inverse_transform(predicted_claims)\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(y_test, color='blue', label='Real Claim Amounts')\n",
    "plt.plot(predicted_claims, color='red', label='Predicted Claim Amounts')\n",
    "plt.title('Insurance Claim Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Claim Amount')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ce077-1929-4354-a65c-3da4ac67e2c6",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "LSTMs are highly effective for time series prediction and sequence-based problems. They can be applied across various business domains like banking, healthcare, and insurance for predicting stock prices, disease progression, and insurance claims, respectively.\n",
    "\n",
    "When using LSTM, always consider the sequence length, data quality, and model complexity. Additionally, ensure that you follow best practices such as regularization, hyperparameter tuning, and proper data preprocessing to build an effective LSTM model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
